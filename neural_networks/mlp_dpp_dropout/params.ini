[net]
layerSizes=784,800,800,4
activations=rectified_linear,rectified_linear,softmax
doDropout=False
dropoutInputProb=0.2
dropoutProb=0.5
wLenLimit=15.0
momentumInitial=0.5
momentumFinal=0.99
momentumT=500.0
[experiment]
digits=0,1,2,3
learningRate = 0.01
minibatchSize = 97
mnistPath=/home/bdol/code/datasets/mnist/mnist_batches.npz
numEpochs = 500
rateDecay = 0.998
checkGradient=False
numEpochsAfterOverfit=5
[program]
debugMode=False
logToFile=True
logFileBaseName=logfiles/log
