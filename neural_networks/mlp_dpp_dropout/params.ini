[net]
layerSizes=784,800,800,10
activations=rectified_linear,rectified_linear,softmax
doDropout=True
dropoutInputProb=0.2
dropoutProb=0.5
wLenLimit=15.0
momentumInitial=0.5
momentumFinal=0.99
momentumT=500.0
[experiment]
digits=0,1,2,3,4,5,6,7,8,9
learningRate = 0.001
minibatchSize = 100
mnistPath=/home/bdol/code/datasets/mnist/mnist_batches.npz
numEpochs = 500
rateDecay = 0.998
checkGradient=False
numEpochsAfterOverfit=100
[program]
debugMode=False
logToFile=True
logFileBaseName=logfiles/log
